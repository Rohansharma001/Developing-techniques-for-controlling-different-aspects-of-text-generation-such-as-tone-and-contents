{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a6a302-3f10-488d-8251-f22e2332d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697F8A9590>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/ml-dtypes/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FB09750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/ml-dtypes/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FB0A050>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/ml-dtypes/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FB0ACD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/ml-dtypes/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FB0B810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/ml-dtypes/\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FAD2350>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow-intel/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FAF9D50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow-intel/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FAEB450>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow-intel/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FB169D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow-intel/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FB17350>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow-intel/\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FB09A90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FB0ACD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FAFA790>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FB09750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001697FAFA410>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow/\n",
      "ERROR: Could not find a version that satisfies the requirement ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel) (from versions: none)\n",
      "ERROR: No matching distribution found for ml-dtypes<0.5.0,>=0.3.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "INFO: pip is looking at multiple versions of tensorflow-intel to determine which version is compatible with other requirements. This could take a while.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "801b6b18-1ba3-4e50-b98a-b1e2fc7d61e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c098c9-d050-4688-88af-6f21e867b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip transformers tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4fab0f6-7be8-4bca-af34-9a5f8b692b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (4.51.3)\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc7b25c-a63f-4ad1-964e-6f840125b2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Loss: 0.0224\n",
      "Epoch [100/300], Loss: 0.0031\n",
      "Epoch [150/300], Loss: 0.0019\n",
      "Epoch [200/300], Loss: 0.0013\n",
      "Epoch [250/300], Loss: 0.0009\n",
      "Epoch [300/300], Loss: 0.0007\n",
      "\n",
      "Generated Text:\n",
      "\n",
      "hello worldxstx tg ea etx t xst st xml ea eta eixetxstgssaxst xt  en mdei eag st staxt xmtxxtihsl et et htxhta\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# Sample text corpus\n",
    "text = \"hello world. this is a simple text generation example using pytorch.\"\n",
    "\n",
    "# Character mappings\n",
    "chars = sorted(list(set(text)))\n",
    "char2idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "idx2char = {idx: ch for idx, ch in enumerate(chars)}\n",
    "\n",
    "# Hyperparameters\n",
    "seq_length = 10\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "lr = 0.003\n",
    "num_epochs = 300\n",
    "\n",
    "# Prepare dataset\n",
    "def create_sequences(text, seq_length):\n",
    "    inputs, targets = [], []\n",
    "    for i in range(len(text) - seq_length):\n",
    "        inputs.append([char2idx[ch] for ch in text[i:i+seq_length]])\n",
    "        targets.append(char2idx[text[i+seq_length]])\n",
    "    return torch.tensor(inputs), torch.tensor(targets)\n",
    "\n",
    "X, y = create_sequences(text, seq_length)\n",
    "\n",
    "# Model definition\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        out, h = self.rnn(x, h)\n",
    "        out = self.fc(out[:, -1, :])  # take output from last time step\n",
    "        return out, h\n",
    "\n",
    "model = CharRNN(len(chars), hidden_size, len(chars), num_layers)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# One-hot encoding function\n",
    "def one_hot_encode(x, dict_size):\n",
    "    result = torch.zeros(x.size(0), x.size(1), dict_size)\n",
    "    for i in range(x.size(0)):\n",
    "        for j in range(x.size(1)):\n",
    "            result[i][j][x[i][j]] = 1\n",
    "    return result\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    h = torch.zeros(num_layers, X.size(0), hidden_size)\n",
    "    inputs = one_hot_encode(X, len(chars))\n",
    "    outputs, h = model(inputs, h.detach())\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Text generation\n",
    "def generate_text(start_seq, length=100):\n",
    "    model.eval()\n",
    "    chars_seq = list(start_seq.lower())\n",
    "    input_seq = torch.tensor([[char2idx[c] for c in chars_seq]])\n",
    "    input_seq = one_hot_encode(input_seq, len(chars))\n",
    "    h = torch.zeros(num_layers, 1, hidden_size)\n",
    "\n",
    "    result = start_seq\n",
    "    for _ in range(length):\n",
    "        output, h = model(input_seq, h)\n",
    "        prob = nn.functional.softmax(output[0], dim=0).data\n",
    "        char_idx = torch.multinomial(prob, 1)[0]\n",
    "        char = idx2char[char_idx.item()]\n",
    "        result += char\n",
    "        input_seq = one_hot_encode(torch.tensor([[char2idx[c] for c in result[-seq_length:]]]), len(chars))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example generation\n",
    "print(\"\\nGenerated Text:\\n\")\n",
    "print(generate_text(\"hello worl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e121329d-64af-45ff-a007-e3b9d779a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/300], Loss: 0.0002\n",
      "Epoch [100/300], Loss: 0.0001\n",
      "Epoch [150/300], Loss: 0.0001\n",
      "Epoch [200/300], Loss: 0.0001\n",
      "Epoch [250/300], Loss: 0.0000\n",
      "Epoch [300/300], Loss: 0.0000\n",
      "\n",
      "Generated Completion:\n",
      "\n",
      "deep learning is subset of machine learning. machine learning. machine learning is a part machine learning. machine learning. machine learning is a part\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Sample corpus\n",
    "corpus = \"\"\"\n",
    "deep learning is a subset of machine learning.\n",
    "machine learning is a part of artificial intelligence.\n",
    "neural networks are used in deep learning.\n",
    "artificial intelligence is transforming the world.\n",
    "data science involves statistics and machine learning.\n",
    "\"\"\"\n",
    "\n",
    "# Preprocessing\n",
    "corpus = corpus.lower().split()\n",
    "vocab = sorted(set(corpus))\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "# Hyperparameters\n",
    "seq_length = 4\n",
    "hidden_size = 128\n",
    "num_layers = 1\n",
    "lr = 0.01\n",
    "num_epochs = 300\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(words, seq_len):\n",
    "    X, y = [], []\n",
    "    for i in range(len(words) - seq_len):\n",
    "        X.append([word2idx[w] for w in words[i:i+seq_len]])\n",
    "        y.append(word2idx[words[i+seq_len]])\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "X, y = create_sequences(corpus, seq_length)\n",
    "\n",
    "# Model\n",
    "class WordLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, 50)\n",
    "        self.lstm = nn.LSTM(50, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embed(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out, hidden\n",
    "\n",
    "model = WordLSTM(len(vocab), hidden_size, num_layers)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    hidden = (torch.zeros(num_layers, X.size(0), hidden_size),\n",
    "              torch.zeros(num_layers, X.size(0), hidden_size))\n",
    "\n",
    "    output, hidden = model(X, hidden)\n",
    "    loss = criterion(output, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Text generation\n",
    "def generate_text(start_words, gen_len=20):\n",
    "    model.eval()\n",
    "    words = start_words.lower().split()\n",
    "    state_h = torch.zeros(num_layers, 1, hidden_size)\n",
    "    state_c = torch.zeros(num_layers, 1, hidden_size)\n",
    "\n",
    "    for _ in range(gen_len):\n",
    "        x = torch.tensor([[word2idx.get(w, 0) for w in words[-seq_length:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_idx = np.random.choice(len(last_word_logits), p=p)\n",
    "\n",
    "        words.append(idx2word[word_idx])\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Example\n",
    "print(\"\\nGenerated Completion:\\n\")\n",
    "print(generate_text(\"deep learning is\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90818025-96fc-47ff-96a7-b519ad8833df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the text:-  wakeup early because\n",
      "Enter the tone type to print:- formal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "\n",
      "It is highly recommended to wake up early because it can have a significant impact on your productivity, mood, and overall well-being. By rising early, you can seize the day and make the most out of your time. Embracing the stillness of the early morning hours allows for increased focus and concentration, enabling you to tackle tasks with a clear mind and heightened energy levels. Additionally, waking up early provides the opportunity to establish a healthy routine, including exercise, proper nutrition, and self-care practices - all of which are essential for a balanced and fulfilling lifestyle. Therefore, setting the habit of waking up early can lead to improved efficiency, enhanced mental clarity, and a greater sense of accomplishment throughout the day.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "openai_client = openai.OpenAI(api_key=\"   ......\")\n",
    "\n",
    "# Function to generate text with tone control using GPT\n",
    "def generate_text_with_gpt(base_content, tone=\"formal\", model=\"gpt-3.5-turbo\"):\n",
    "    # Step 1: Create a system prompt\n",
    "    system_prompt = f\"You are an expert content writer. Write the text in a {tone} tone.\"\n",
    "\n",
    "    # Step 2: Create user prompt\n",
    "    user_prompt = f\"Base content: {base_content}\\n\\nGenerate the final text accordingly.\"\n",
    "\n",
    "    # Step 3: Call OpenAI GPT API (New Format)\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Step 4: Extract and return the generated content\n",
    "    final_text = response.choices[0].message.content.strip()\n",
    "    return final_text\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Input content\n",
    "    base_content = input('Enter the text:- ')\n",
    "\n",
    "    # Control settings\n",
    "    tone = input(\"Enter the tone type to print:-\")  # Try formal, casual, friendly, emotional, professional, etc.\n",
    "\n",
    "    # Generate controlled text using GPT\n",
    "    result = generate_text_with_gpt(base_content, tone)\n",
    "    print(\"Generated Text:\\n\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb32306-b38d-4819-98e5-cbc08da23b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7fe085-41b8-4b64-9f4f-93e32a5706a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Gui text generator\n",
    "\n",
    "# Module import\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk  # Pillow library\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "# import mysql.connector\n",
    "# from mysql.connector import Error\n",
    "import openai\n",
    "\n",
    "\n",
    "\n",
    "# Create GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Generator with Tone\")\n",
    "root.geometry(\"900x700\")\n",
    "root.configure(bg='black')\n",
    "\n",
    "\n",
    "\n",
    "openai_client=openai.OpenAI(api_key=\".....\")\n",
    "\n",
    "def generate_text_with_gpt(base_content, tone=\"formal\", model=\"gpt-3.5-turbo\"):\n",
    "    # Api key insert \n",
    "    # openai_client=openai.OpenAI(api_key=\"......\")\n",
    "    \n",
    "    # Step 1: Create a system prompt\n",
    "    system_prompt = f\"You are an expert content writer. Write the text in a {tone} tone.\"\n",
    "\n",
    "    # Step 2: Create user prompt\n",
    "    user_prompt = f\"Base content: {base_content}\\n\\nGenerate the final text accordingly.\"\n",
    "\n",
    "    # Step 3: Call OpenAI GPT API (New Format)\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    # Step 4: Extract and return the generated content\n",
    "    final_text = response.choices[0].message.content.strip()\n",
    "    return final_text\n",
    "\n",
    "def text():\n",
    "    openai_client=openai.OpenAI(api_key=\",......\")\n",
    "    \n",
    "    k=Text_entry.get()\n",
    "    k2=Tone_entry.get()\n",
    "    result = generate_text_with_gpt(k,k2)\n",
    "    # print(result)\n",
    "    # generated_output=result\n",
    "    # print(generated_output)\n",
    "    generated_output.insert(tk.END,result)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# Text Label & Entry\n",
    "tk.Label(root, text=\"Enter Text:\",font=(\"Arial\", 15),bg=\"lightblue\").grid(row=0, column=0, padx=10,pady=10)\n",
    "Text_entry = tk.Entry(root, font=(\"Arial\", 15), width=50)\n",
    "Text_entry.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "# Tone Label & Entry\n",
    "tk.Label(root, text=\"Tone Type:\",font=(\"Arial\", 15),bg=\"lightblue\").grid(row=1,column=0, padx=10, pady=10)\n",
    "Tone_entry = tk.Entry(root, font=(\"Arial\", 15), width=50)\n",
    "Tone_entry.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "# Generate Button\n",
    "tk.Button(root, text=\"Generate Text\", command=text, font=(\"Arial\", 15), bg=\"lightgreen\").grid(row=2, columnspan=2, pady=20)\n",
    "\n",
    "# Output Label & Text Area\n",
    "tk.Label(root, text=\"Generated Output:\",font=(\"Arial\", 15),bg=\"lime\").grid(row=3,column=0,padx=10,pady=10)\n",
    "generated_output = tk.Text(root,font=(\"Arial\", 14),width=70,height=10,wrap=tk.WORD, bg=\"lightyellow\")\n",
    "generated_output.grid(row=4, columnspan=2, padx=20, pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
